{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOVb0KkrGG7aK7GZnJ0+2X/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bT7YXE3pQWzG","executionInfo":{"status":"ok","timestamp":1705936596261,"user_tz":-480,"elapsed":6771,"user":{"displayName":"MUHAMMAD FARIS BIN SHAIK MOHAMED","userId":"13453467460975254241"}},"outputId":"a5df24e1-3a1f-4982-91b6-576ca0173a98"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["!pip install pyheif\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tUDipHq3U5rn","executionInfo":{"status":"ok","timestamp":1705648365678,"user_tz":-480,"elapsed":10247,"user":{"displayName":"MUHAMMAD FARIS BIN SHAIK MOHAMED","userId":"13453467460975254241"}},"outputId":"506b04cd-d801-43bb-e408-d912f29e8b4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyheif\n","  Downloading pyheif-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyheif) (1.16.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.0->pyheif) (2.21)\n","Installing collected packages: pyheif\n","Successfully installed pyheif-0.7.1\n"]}]},{"cell_type":"code","source":["import os\n","from PIL import Image\n","import pyheif\n","\n","\n","heic_path = '/content/drive/My Drive/Project/Fish_Pre/Fish/Test/Jenahak'\n","\n","\n","png_path = '/content/drive/My Drive/Project/Fish_Pre/Fish/Test/Jenahak'\n","\n","heic_files = os.listdir(heic_path)\n","\n","for file in heic_files:\n","    if file.endswith('.HEIC') or file.endswith('.heic'):\n","        heic_file_path = os.path.join(heic_path, file)\n","        heif_file = pyheif.read(heic_file_path)\n","        image = Image.frombytes(\n","            heif_file.mode,\n","            heif_file.size,\n","            heif_file.data,\n","            \"raw\",\n","            heif_file.mode,\n","            heif_file.stride,\n","        )\n","\n","        png_file_path = os.path.join(png_path, os.path.splitext(file)[0] + '.png')\n","        image.save(png_file_path, 'PNG')\n"],"metadata":{"id":"uS3c1n8OXBZ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#jpg to png\n","import os\n","from PIL import Image\n","\n","jpg_path = '/content/drive/My Drive/Project/NA_Fish_Dataset/Tamok'\n","png_path = '/content/drive/My Drive/Project/NA_Fish_Dataset/Tamok_PNG'\n","\n","jpg_files = os.listdir(jpg_path)\n","\n","for file in jpg_files:\n","    if file.endswith('.jpg') or file.endswith('.jpeg') or file.endswith('.JPG') or file.endswith('.JPEG'):\n","        jpg_file_path = os.path.join(jpg_path, file)\n","        image = Image.open(jpg_file_path)\n","\n","        png_file_path = os.path.join(png_path, os.path.splitext(file)[0] + '.png')\n","        image.save(png_file_path, 'PNG')\n","\n"],"metadata":{"id":"k_84a0R47p5z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for file in os.listdir(png_path):\n","    image_path = os.path.join(png_path, file)\n","    img = Image.open(image_path)\n","    img = img.rotate(90, expand=True)\n","    img.save(image_path)\n"],"metadata":{"id":"KakP5NeJZdsK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install opencv-python\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ghnsBXO9qgNf","executionInfo":{"status":"ok","timestamp":1704200960790,"user_tz":-480,"elapsed":11438,"user":{"displayName":"MUHAMMAD FARIS BIN SHAIK MOHAMED","userId":"13453467460975254241"}},"outputId":"5425f0a5-79f6-4a99-b725-03b9648d357e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n"]}]},{"cell_type":"code","source":["#Crop to same pixel for every images\n","import os\n","from PIL import Image\n","from google.colab import drive\n","\n","# Step 1: Function to crop PNG images\n","def crop_png_images(input_folder, output_folder, target_size=(4000, 3000)):\n","    for filename in os.listdir(input_folder):\n","        if filename.endswith(\".png\"):\n","            input_path = os.path.join(input_folder, filename)\n","            output_path = os.path.join(output_folder, filename)\n","\n","            # Open the image\n","            img = Image.open(input_path)\n","\n","            # Get the center coordinates\n","            width, height = img.size\n","            left = (width - target_size[0]) / 2\n","            top = (height - target_size[1]) / 2\n","            right = (width + target_size[0]) / 2\n","            bottom = (height + target_size[1]) / 2\n","\n","            # Crop the image\n","            cropped_img = img.crop((left, top, right, bottom))\n","\n","            # Save the cropped image\n","            cropped_img.save(output_path, format=\"PNG\")\n","\n","input_folder = '/content/drive/My Drive/Project/NA_Fish_Dataset/Daun baru.png'\n","output_folder = '/content/drive/My Drive/Project/NA_Fish_Dataset/Daun baru.png'\n","\n","if not os.path.exists(output_folder):\n","    os.makedirs(output_folder)\n","\n","crop_png_images(input_folder, output_folder, target_size=(4000, 3000))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BydqjV1o2Nov","executionInfo":{"status":"ok","timestamp":1704602651223,"user_tz":-480,"elapsed":151159,"user":{"displayName":"MUHAMMAD FARIS BIN SHAIK MOHAMED","userId":"13453467460975254241"}},"outputId":"6fce4fbc-8d28-443e-e983-16b95ca92fbd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["#image resize\n","from PIL import Image\n","import os\n","\n","png_path = '/content/drive/My Drive/Project/NA_Fish_Dataset/Tenggiri.Png.Cropped'\n","\n","for file in os.listdir(png_path):\n","    image_path = os.path.join(png_path, file)\n","    try:\n","        img = Image.open(image_path)\n","        img = img.resize((244, 445), Image.LANCZOS)\n","        img.save(image_path)\n","    except FileNotFoundError:\n","        print(f\"File {file} not found. Skipping...\")\n","    except Exception as e:\n","        print(f\"Error processing {file}: {e}\")\n","\n","\n"],"metadata":{"id":"kMak3vAUdqLn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#flip\n","from PIL import Image\n","import os\n","\n","def flip_with_black_padding(image, method):\n","    if method == \"left\":\n","        return image.transpose(Image.FLIP_LEFT_RIGHT)\n","    elif method == \"right\":\n","        return image.transpose(Image.FLIP_TOP_BOTTOM)\n","    elif method == \"up\":\n","        return image.transpose(Image.FLIP_LEFT_RIGHT).transpose(Image.FLIP_TOP_BOTTOM)\n","    elif method == \"down\":\n","        return image\n","    else:\n","        return image\n","\n","root_path = '/content/drive/My Drive/Project'\n","input_base_path = 'Fish_Dataset'\n","output_base_path = 'Fish_Dataset_Augmented'\n","\n","species_list = [\"BawalEmas\",\"Cencaru\",\"DaunBaru\",\"Gelama\",\"Jenahak\",\"Kembong\",\"Kerisi\",\"Merah\",\"Sardin\",\"Sebelah\",\"SelarKuning\",\"Senangin\",\"Siakap\",\"Tamok\",\"TilapiaMerah\"]\n","for species in species_list:\n","    png_path = os.path.join(root_path, input_base_path, species)\n","    output_dir = os.path.join(root_path, output_base_path, species)\n","\n","    for file in os.listdir(png_path):\n","        image_path = os.path.join(png_path, file)\n","        img = Image.open(image_path)\n","        for flip_method in [\"left\", \"right\", \"up\", \"down\"]:\n","            flipped_img = flip_with_black_padding(img, flip_method)\n","            new_file_name = f\"{os.path.splitext(file)[0]}_flipped_{flip_method}.png\"\n","            flipped_img.save(os.path.join(output_dir, new_file_name))\n","\n"],"metadata":{"id":"-hRaQ130PgxG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#rotate 90 vertical\n","from PIL import Image\n","import os\n","\n","root_path = '/content/drive/My Drive/Project'\n","input_base_path = 'Fish_Dataset'\n","output_base_path = 'Fish_Dataset_Augmented'\n","\n","species_list = [\"BawalEmas\",\"Cencaru\",\"DaunBaru\",\"Gelama\",\"Jenahak\",\"Kembong\",\"Kerisi\",\"Merah\",\"Sardin\",\"Sebelah\",\"SelarKuning\",\"Senangin\",\"Siakap\",\"Tamok\",\"TilapiaMerah\"]\n","\n","for species in species_list:\n","    png_path = os.path.join(root_path, input_base_path, species)\n","    output_dir = os.path.join(root_path, output_base_path, species)\n","\n","    for file in os.listdir(png_path):\n","        image_path = os.path.join(png_path, file)\n","        img = Image.open(image_path)\n","\n","        # Rotate by 90 degrees\n","        rotated_img_90 = img.rotate(90, expand=True)\n","        new_file_name_90 = f\"{os.path.splitext(file)[0]}_rotated_90.png\"\n","        rotated_img_90.save(os.path.join(output_dir, new_file_name_90))\n","\n","        # Rotate by -90 degrees\n","        rotated_img_minus_90 = img.rotate(-90, expand=True)\n","        new_file_name_minus_90 = f\"{os.path.splitext(file)[0]}_rotated_minus_90.png\"\n","        rotated_img_minus_90.save(os.path.join(output_dir, new_file_name_minus_90))\n","\n"],"metadata":{"id":"fUg1jW5bh92f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Rotate 20, 40 horizontal\n","import os\n","import cv2\n","\n","root_path = '/content/drive/My Drive/Project'\n","input_base_path = 'Fish_Dataset'\n","output_base_path = 'Fish_Dataset_Augmented'\n","\n","species_list = [\"BawalEmas\",\"Cencaru\",\"DaunBaru\",\"Gelama\",\"Jenahak\",\"Kembong\",\"Kerisi\",\"Merah\",\"Sardin\",\"Sebelah\",\"SelarKuning\",\"Senangin\",\"Siakap\",\"Tamok\",\"TilapiaMerah\"]  # Add your 15 species here\n","\n","for species in species_list:\n","    data_dir = os.path.join(root_path, input_base_path, species)\n","    output_dir = os.path.join(root_path, output_base_path, species)\n","\n","    for filename in os.listdir(data_dir):\n","        img_path = os.path.join(data_dir, filename)\n","        img = cv2.imread(img_path)\n","\n","        if img is not None:\n","            height, width = img.shape[:2]\n","\n","            # Rotate by 20 degrees\n","            angle_20 = 20\n","            rotation_matrix_20 = cv2.getRotationMatrix2D((width / 2, height / 2), angle_20, 1)\n","            rotated_img_20 = cv2.warpAffine(img, rotation_matrix_20, (width, height), borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0))\n","            output_path_20 = os.path.join(output_dir, f\"rotated_20_{filename}\")\n","            cv2.imwrite(output_path_20, rotated_img_20)\n","\n","            # Rotate by 40 degrees\n","            angle_40 = 40\n","            rotation_matrix_40 = cv2.getRotationMatrix2D((width / 2, height / 2), angle_40, 1)\n","            rotated_img_40 = cv2.warpAffine(img, rotation_matrix_40, (width, height), borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0))\n","            output_path_40 = os.path.join(output_dir, f\"rotated_40_{filename}\")\n","            cv2.imwrite(output_path_40, rotated_img_40)\n"],"metadata":{"id":"-roW2mItk2oQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#translation\n","import os\n","from PIL import Image\n","import numpy as np\n","\n","root_path = '/content/drive/My Drive/Project'\n","input_base_path = 'Fish_Dataset'\n","output_base_path = 'Fish_Dataset_Augmented'\n","\n","species_list = [\"BawalEmas\", \"Cencaru\", \"DaunBaru\", \"Gelama\", \"Jenahak\", \"Kembong\", \"Kerisi\", \"Merah\", \"Sardin\", \"Sebelah\", \"SelarKuning\", \"Senangin\", \"Siakap\", \"Tamok\", \"TilapiaMerah\"]\n","\n","# Create the output directory if it doesn't exist\n","output_directory = os.path.join(root_path, output_base_path)\n","os.makedirs(output_directory, exist_ok=True)\n","\n","# Function to load an image\n","def load_image(path):\n","    img = Image.open(path)\n","    return img\n","\n","# Function to perform translation (shift) augmentation\n","def translate_image(img, tx, ty):\n","    width, height = img.size\n","    translated_img = Image.new('RGB', (width, height))\n","    translated_img.paste(img, (tx, ty))\n","    return translated_img\n","\n","# Define maximum translation distances in pixels (adjust as needed)\n","max_tx = 700  # Maximum horizontal shift (positive or negative)\n","max_ty = 700  # Maximum vertical shift (positive or negative)\n","\n","# Number of augmented images to generate for each original image\n","num_augmentations = 1\n","\n","# Iterate over each species\n","for species in species_list:\n","    input_species_path = os.path.join(root_path, input_base_path, species)\n","    output_species_path = os.path.join(output_directory, species.replace(\" \", \"_\"))\n","    os.makedirs(output_species_path, exist_ok=True)\n","\n","    # Iterate over the images in the species directory\n","    for root, _, files in os.walk(input_species_path):\n","        for file in files:\n","            if file.endswith('.JPG') or file.endswith('.jpg') or file.endswith('.png'):\n","                img_path = os.path.join(root, file)\n","\n","                # Load the image\n","                img = load_image(img_path)\n","\n","                # Generate and apply exactly 10 random translation (shift) augmentations\n","                for i in range(num_augmentations):\n","                    # Generate random translation distances\n","                    tx = np.random.randint(-max_tx, max_tx + 1)\n","                    ty = np.random.randint(-max_ty, max_ty + 1)\n","\n","                    # Perform translation (shift) augmentation\n","                    augmented_img = translate_image(img, tx, ty)\n","\n","                    # Save the augmented image\n","                    augmented_img.save(os.path.join(output_species_path, f'T_{i}_{file}'))\n","\n","\n"],"metadata":{"id":"cEHRtV7lp_n3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","import os\n","\n","# Set the directory path\n","directory = '/content/drive/My Drive/Project/Fish_Dataset_Augmented'  # Change this path to your dataset location\n","\n","# Set the batch size\n","batch_size = 32\n","\n","# Create an ImageDataGenerator with no augmentation\n","datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Create the generator to retrieve the class information\n","data_generator = datagen.flow_from_directory(\n","    directory,\n","    batch_size=batch_size,\n","    class_mode='categorical',  # Specify the class mode\n","    shuffle=False  # Disable shuffling to maintain the order of classes\n",")\n","\n","# Get the number of images belonging to each class\n","class_counts = data_generator.classes\n","class_labels = list(data_generator.class_indices.keys())\n","\n","# Count the number of images in each class directory\n","class_counts_actual = {}\n","for class_label in class_labels:\n","    class_path = os.path.join(directory, class_label)\n","    num_images = len(os.listdir(class_path))\n","    class_counts_actual[class_label] = num_images\n","\n","# Print the number of images belonging to each class\n","for species_list, count in class_counts_actual.items():\n","    print(f\"{species_list}: {count} images\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_1wjA-gwy-Hj","executionInfo":{"status":"ok","timestamp":1705939565799,"user_tz":-480,"elapsed":602,"user":{"displayName":"MUHAMMAD FARIS BIN SHAIK MOHAMED","userId":"13453467460975254241"}},"outputId":"d3a70201-c3b0-4a0e-dab2-fbb227013135"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 4500 images belonging to 15 classes.\n","BawalEmas: 300 images\n","Cencaru: 300 images\n","DaunBaru: 300 images\n","Gelama: 300 images\n","Jenahak: 300 images\n","Kembong: 300 images\n","Kerisi: 300 images\n","Merah: 300 images\n","Sardin: 300 images\n","Sebelah: 300 images\n","SelarKuning: 300 images\n","Senangin: 300 images\n","Siakap: 300 images\n","Tamok: 300 images\n","TilapiaMerah: 300 images\n"]}]}]}